{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31cf02a",
   "metadata": {},
   "source": [
    "## Filtrado basado en contenido con una red neuronal\n",
    "\n",
    "En el laboratorio de filtrado colaborativo, generaste dos vectores: un vector de usuario y un vector de ítem/película, cuyo producto punto predeciría una calificación. Estos vectores se derivaron únicamente de las calificaciones.\n",
    "\n",
    "El filtrado basado en contenido también genera un vector de características de usuario y de película, pero reconoce que puede haber otra información disponible sobre el usuario y/o la película que pueda mejorar la predicción. Esta información adicional se proporciona a una red neuronal que luego genera los vectores de usuario y película como se muestra a continuación.\n",
    "\n",
    "<figure>\n",
    "    <center> <img src=\"./img/RecSysNN.png\"   style=\"width:500px;height:280px;\" ></center>\n",
    "</figure>\n",
    "\n",
    "La información de la película proporcionada a la red es una combinación de los datos originales y algunas \"características diseñadas\". Las características originales son el año de lanzamiento de la película y el género de la película presentado como un vector one-hot. Hay 14 géneros. La característica diseñada es una calificación promedio derivada de las calificaciones de los usuarios. Las películas con múltiples géneros tienen un vector de entrenamiento por género.\n",
    "\n",
    "El contenido del usuario está compuesto únicamente por características diseñadas. Se calcula un promedio de calificaciones por género para cada usuario. Además, hay disponible un ID de usuario, un recuento de calificaciones y un promedio de calificaciones, pero no se incluyen en el contenido de entrenamiento o predicción. Son útiles para interpretar los datos.\n",
    "\n",
    "El conjunto de entrenamiento consiste en todas las calificaciones realizadas por los usuarios en el conjunto de datos. Los vectores de usuario y película/ítem se presentan a la red anterior juntos como un conjunto de entrenamiento. El vector de usuario es el mismo para todas las películas calificadas por el usuario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c95b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "#minmaxscaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import IterableDataset, DataLoader, get_worker_info\n",
    "\n",
    "import pyarrow.dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367f55f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208da63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RecommenderDataset(Dataset):\n",
    "#     def __init__(self, user_features, item_features, targets,\n",
    "#                  user_scaler=None, item_scaler=None, target_scaler=None):\n",
    "#         \"\"\"\n",
    "#         Dataset para sistema de recomendación content-based.\n",
    "#         Recibe datos YA escalados, y opcionalmente guarda los escalers usados.\n",
    "#         \"\"\"\n",
    "#         self.user_features = torch.tensor(user_features, dtype=torch.float32)\n",
    "#         self.item_features = torch.tensor(item_features, dtype=torch.float32)\n",
    "#         self.targets       = torch.tensor(targets      , dtype=torch.float32)\n",
    "# \n",
    "#         self.user_scaler   = user_scaler\n",
    "#         self.item_scaler   = item_scaler\n",
    "#         self.target_scaler = target_scaler\n",
    "# \n",
    "#     def __len__(self):\n",
    "#         return len(self.targets)\n",
    "# \n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.user_features[idx], self.item_features[idx], self.targets[idx]\n",
    "# \n",
    "#     @classmethod\n",
    "#     def from_split(cls, user_features, item_features, targets,\n",
    "#                    test_size=0.2, random_state=31415):\n",
    "#         \"\"\"\n",
    "#         Divide los datos en train/test, ajusta los scalers solo con train,\n",
    "#         transforma ambos y devuelve los datasets listos.\n",
    "#         \"\"\"\n",
    "# \n",
    "#         X_user_train, X_user_test, X_item_train, X_item_test, y_train, y_test = train_test_split(\n",
    "#             user_features, item_features, targets, test_size=test_size, random_state=random_state, stratify=targets\n",
    "#         )\n",
    "# \n",
    "# \n",
    "#         user_scaler   = StandardScaler()\n",
    "#         item_scaler   = StandardScaler()\n",
    "#         target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# \n",
    "#         X_user_train = user_scaler.fit_transform(X_user_train)\n",
    "#         X_item_train = item_scaler.fit_transform(X_item_train)\n",
    "#         y_train      = target_scaler.fit_transform(y_train)\n",
    "# \n",
    "#         X_user_test = user_scaler.transform(X_user_test)\n",
    "#         X_item_test = item_scaler.transform(X_item_test)\n",
    "#         y_test      = target_scaler.transform(y_test)\n",
    "# \n",
    "#         train_ds = cls(X_user_train, X_item_train, y_train,\n",
    "#                        user_scaler, item_scaler, target_scaler)\n",
    "#         test_ds  = cls(X_user_test, X_item_test, y_test,\n",
    "#                        user_scaler, item_scaler, target_scaler)\n",
    "# \n",
    "#         return train_ds, test_ds\n",
    "# \n",
    "\n",
    "\n",
    "class InteractionDataset(IterableDataset):\n",
    "    def __init__(self, interactions_path, user_feat, item_feat, u_map, i_map, batch_size=4096, max_rows=None):\n",
    "        self.user_feat  = user_feat\n",
    "        self.item_feat  = item_feat\n",
    "        self.u_map      = u_map\n",
    "        self.i_map      = i_map\n",
    "\n",
    "        # batch_size = tamaño de lectura (NO de entrenamiento)\n",
    "        self.batch_size = batch_size\n",
    "        self.max_rows   = max_rows\n",
    "\n",
    "        # Leer SOLO columnas necesarias\n",
    "        self.dataset = ds.dataset(\n",
    "            interactions_path,\n",
    "            format=\"parquet\"\n",
    "        )\n",
    "    def __len__(self):\n",
    "        if self.max_rows is not None:\n",
    "            return min(self.max_rows, self.dataset.count_rows())\n",
    "        return self.dataset.count_rows()\n",
    "\n",
    "    def __iter__(self):\n",
    "        #worker  = get_worker_info()\n",
    "        counter = 0\n",
    "        for idx, batch in enumerate(self.dataset.to_batches(batch_size=self.batch_size)):\n",
    "            #if idx % worker.num_workers != worker.id:\n",
    "            #    continue\n",
    "            yield from self._process_batch(batch)\n",
    "            counter+=1\n",
    "            if self.max_rows is not None and counter >= self.max_rows:\n",
    "                return\n",
    "\n",
    "\n",
    "    def _process_batch(self, batch):\n",
    "        table = batch.to_pydict()\n",
    "\n",
    "        user_ids = np.asarray(table[\"userID\"] , dtype=np.int32)\n",
    "        item_ids = np.asarray(table[\"animeID\"], dtype=np.int32)\n",
    "        #labels   = np.asarray(table[\"label\"]  , dtype=np.float32)\n",
    "        ratings  = np.asarray(table[\"rating\"] , dtype=np.float32)\n",
    "\n",
    "        u_idx = np.fromiter((self.u_map.get(u, -1) for u in user_ids), dtype=np.int32, count=len(user_ids))\n",
    "        i_idx = np.fromiter((self.i_map.get(i, -1) for i in item_ids), dtype=np.int32, count=len(item_ids))\n",
    "\n",
    "        mask = (u_idx >= 0) & (i_idx >= 0)\n",
    "        if not mask.any():\n",
    "            return\n",
    "\n",
    "\n",
    "        yield {\n",
    "            # IDs (solo para evaluación / logging)\n",
    "            \"user_id\": torch.from_numpy(user_ids[mask]),\n",
    "            \"item_id\": torch.from_numpy(item_ids[mask]),\n",
    "\n",
    "            # Features (input real del modelo)\n",
    "            \"user_batch\": torch.from_numpy(self.user_feat[u_idx[mask]]),\n",
    "            \"item_batch\": torch.from_numpy(self.item_feat[i_idx[mask]]),\n",
    "\n",
    "            # Targets\n",
    "            \"rating\": torch.from_numpy(ratings[mask]),\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e952ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../../data/data_anime/prod/\"\n",
    "\n",
    "#Users\n",
    "user_df = pd.read_parquet(data_root+\"user_final\")\n",
    "user_df = user_df.set_index(\"userID\").sort_index()\n",
    "\n",
    "#Items\n",
    "item_df = pd.read_parquet(data_root+\"item_final\")\n",
    "item_df = item_df.set_index(\"animeID\").sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a195c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a808e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "\n",
    "#train = pd.read_parquet(data_root + \"train_interactions\")\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train, test = train_test_split(train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fb1ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=32, hidden_dim=[256, 128], p=0.5):\n",
    "        super(encoder, self).__init__()\n",
    "        layers = []\n",
    "        dims = [input_dim] + hidden_dim + [embedding_dim]\n",
    "        for i in range(len(dims) - 2):\n",
    "            layers.extend(\n",
    "                [\n",
    "                    nn.Linear(dims[i], dims[i + 1]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(p=p),\n",
    "                ]\n",
    "            )\n",
    "        layers.append(nn.Linear(dims[-2], dims[-1]))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, nn.Linear): nn.init.normal_(layer.weight, std=0.01)\n",
    "        \n",
    "\n",
    "        #self.net = nn.Sequential(\n",
    "        # nn.Linear(input_dim, 256), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "        # nn.Linear(256, 128)      , nn.ReLU(), nn.Dropout(p=0.5),\n",
    "        # nn.Linear(128, embedding_dim)\n",
    "        #)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #return nn.functional.normalize(self.net(x), dim=1, eps=1e-8)\n",
    "        return self.net(x)\n",
    "\n",
    "class UserBasesFiltering(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_user_features, \n",
    "        num_item_features, \n",
    "        embedding_dim=32, \n",
    "        hidden_dim=[256, 128],\n",
    "        p=0.5):\n",
    "\n",
    "        super(UserBasesFiltering, self).__init__()\n",
    "        self.user_tower = encoder(num_user_features, embedding_dim, hidden_dim, p)\n",
    "        self.item_tower = encoder(num_item_features, embedding_dim, hidden_dim, p)\n",
    "\n",
    "    def forward(self, user_features, item_features):\n",
    "        u_emb = self.user_tower(user_features)    # (batch, embedding_dim)\n",
    "        i_emb = self.item_tower(item_features)    # (batch, embedding_dim)\n",
    "\n",
    "        #score = (u_emb * i_emb).sum(dim=1, keepdim=True)   #Ahora se usa aprendizaje costrastivo\n",
    "\n",
    "        #return score  # (batch, 1)\n",
    "        return u_emb, i_emb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac41e13",
   "metadata": {},
   "source": [
    "Lo siguiente tiene un problema, si bien la informacion de \"year\", \"episodes\" y \"score\" son features muy interezantes para un sistema de recomendación, no son features que se puedan usar directamente en el modelo. \n",
    "\n",
    "Estos features pueden hacer que el modelo sature rapidamente, haciendo que el modelo no aprenda a predecir la similitud entre los items.\n",
    "\n",
    "Los features son discretos y el rango que tienen es\n",
    "\n",
    "* year: {1907,...,2026}\n",
    "* episodes: {0,...,3057}\n",
    "* score: {1,...,10}\n",
    "\n",
    "Estos son rangos del set de entrenamiento, por lo que pude varian un poco en el set de testeo, aun así uno quiere tratar de scalar estos valores.\n",
    "Se quiere lograr la tipica normalización de datos.\n",
    "Los rangos propuestos son los siguienes.\n",
    "\n",
    "* year: {1907,...,2026} -> {1900,...,2030}\n",
    "* episodes: {0,...,3057} -> {0,...,4000} Seguro One piece jeje, pero hay de 10mil masomenos, son muy pocos, no los considero\n",
    "* score: {1,...,10} -> {0,...,10}\n",
    "\n",
    "y con esto puedo escalar por min_max scaler. y llevarlos a un rango de {0,1}\n",
    "\n",
    "$x_{scaled} = (x - x_{min})/ (x_{max}-x_{min})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b0ed4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>episodes</th>\n",
       "      <th>year</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "      <th>319</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19598.000000</td>\n",
       "      <td>19598.000000</td>\n",
       "      <td>19598.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.00000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "      <td>19483.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.312016</td>\n",
       "      <td>12.832177</td>\n",
       "      <td>2008.612256</td>\n",
       "      <td>0.268080</td>\n",
       "      <td>0.011395</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>0.010419</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.011035</td>\n",
       "      <td>0.011138</td>\n",
       "      <td>0.015347</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>0.010111</td>\n",
       "      <td>0.00811</td>\n",
       "      <td>0.012421</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>0.006980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.008972</td>\n",
       "      <td>61.998038</td>\n",
       "      <td>14.765114</td>\n",
       "      <td>0.442971</td>\n",
       "      <td>0.106138</td>\n",
       "      <td>0.123938</td>\n",
       "      <td>0.101545</td>\n",
       "      <td>0.094350</td>\n",
       "      <td>0.105902</td>\n",
       "      <td>0.100299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113436</td>\n",
       "      <td>0.104470</td>\n",
       "      <td>0.104950</td>\n",
       "      <td>0.122931</td>\n",
       "      <td>0.123536</td>\n",
       "      <td>0.100048</td>\n",
       "      <td>0.08969</td>\n",
       "      <td>0.110758</td>\n",
       "      <td>0.122322</td>\n",
       "      <td>0.083259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1907.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.610000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.340000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.040000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>3057.000000</td>\n",
       "      <td>2026.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              score      episodes          year             0             1  \\\n",
       "count  19598.000000  19598.000000  19598.000000  19483.000000  19483.000000   \n",
       "mean       6.312016     12.832177   2008.612256      0.268080      0.011395   \n",
       "std        1.008972     61.998038     14.765114      0.442971      0.106138   \n",
       "min        1.730000      0.000000   1907.000000      0.000000      0.000000   \n",
       "25%        5.610000      1.000000   2003.000000      0.000000      0.000000   \n",
       "50%        6.340000      2.000000   2013.000000      0.000000      0.000000   \n",
       "75%        7.040000     12.000000   2019.000000      1.000000      0.000000   \n",
       "max       10.000000   3057.000000   2026.000000      1.000000      1.000000   \n",
       "\n",
       "                  2             3             4             5             6  \\\n",
       "count  19483.000000  19483.000000  19483.000000  19483.000000  19483.000000   \n",
       "mean       0.015603      0.010419      0.008982      0.011343      0.010163   \n",
       "std        0.123938      0.101545      0.094350      0.105902      0.100299   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...           310           311           312           313  \\\n",
       "count  ...  19483.000000  19483.000000  19483.000000  19483.000000   \n",
       "mean   ...      0.013037      0.011035      0.011138      0.015347   \n",
       "std    ...      0.113436      0.104470      0.104950      0.122931   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                314           315          316           317           318  \\\n",
       "count  19483.000000  19483.000000  19483.00000  19483.000000  19483.000000   \n",
       "mean       0.015501      0.010111      0.00811      0.012421      0.015193   \n",
       "std        0.123536      0.100048      0.08969      0.110758      0.122322   \n",
       "min        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.00000      1.000000      1.000000   \n",
       "\n",
       "                319  \n",
       "count  19483.000000  \n",
       "mean       0.006980  \n",
       "std        0.083259  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 323 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df.describe()\n",
    "#claramente la cantidad de episodios no es gaussiana, no puedo usar StandardScaler.\n",
    "# Si podria con score, ahi muy justo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30361813",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MinMaxScaler(nn.Module):\n",
    "    def __init__(self, min_val, max_val, log=False, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.log = log\n",
    "        self.eps = eps\n",
    "\n",
    "        self.register_buffer(\"min\", torch.tensor(min_val, dtype=torch.float32))\n",
    "        self.register_buffer(\"max\", torch.tensor(max_val, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.log:\n",
    "            x = torch.log1p(x)\n",
    "            minv = torch.log1p(self.min)\n",
    "            maxv = torch.log1p(self.max)\n",
    "        else:\n",
    "            minv, maxv = self.min, self.max\n",
    "\n",
    "        x = (x - minv) / (maxv - minv + self.eps)\n",
    "        return torch.clamp(x, 0.0, 1.0)\n",
    "\n",
    "class ItemFeaturePipeline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.year     = MinMaxScaler(1_900, 2_030)\n",
    "        self.episodes = MinMaxScaler(0, 4_000, log=True)\n",
    "        self.score    = MinMaxScaler(0, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x[:, 0] = self.year(x[:, 0])\n",
    "        x[:, 1] = self.episodes(x[:, 1])\n",
    "        x[:, 2] = self.score(x[:, 2])\n",
    "\n",
    "        #return torch.tensor(x, dtype=torch.float32)\n",
    "        # If you need to detach from the computation graph\n",
    "        return x.clone().detach().to(dtype=torch.float32)\n",
    "\n",
    "class UserFeaturePipeline(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.clamp(x / 10.0, 0.0, 1.0)\n",
    "\n",
    "\n",
    "\n",
    "# --- USERS ---\n",
    "user_pipeline = UserFeaturePipeline().to(device)\n",
    "user_tensor   = torch.tensor(user_df.values, dtype=torch.float32, device=device)\n",
    "user_features = user_pipeline(user_tensor).cpu().numpy()\n",
    "\n",
    "user_id_to_row = {uid: i for i, uid in enumerate(user_df.index)}\n",
    "\n",
    "# --- ITEMS ---\n",
    "item_pipeline = ItemFeaturePipeline().to(device)\n",
    "item_tensor   = torch.tensor( item_df.fillna(0).values, dtype=torch.float32, device=device)\n",
    "item_features = item_pipeline(item_tensor).cpu().numpy()\n",
    "\n",
    "item_id_to_row = {iid: i for i, iid in enumerate(item_df.index)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d4d855",
   "metadata": {},
   "source": [
    "Osea que solo me va a poder recomendar peliculas desde 1900 hasta 2030, habra que darle mantenimiento en el 2030 a este jeje!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08abb0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_train = InteractionDataset(\n",
    "    data_root+\"train_interactions\",\n",
    "    user_features,\n",
    "    item_features,\n",
    "    user_id_to_row,\n",
    "    item_id_to_row,\n",
    "    batch_size = 64,\n",
    "    max_rows= None #100_000#64*100\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=None,          # OBLIGATORIO con IterableDataset batchificado\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "\n",
    "dataset_test = InteractionDataset(\n",
    "    data_root+\"test_data\",\n",
    "    user_features,\n",
    "    item_features,\n",
    "    user_id_to_row,\n",
    "    item_id_to_row,\n",
    "    batch_size = 64,\n",
    "    max_rows= None#20_000\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=None,\n",
    "    pin_memory=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a6fbfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Collect all ratings\n",
    "all_ratings = []\n",
    "for batch in train_loader:\n",
    "    all_ratings.extend(batch[\"rating\"].numpy())\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "all_ratings = np.array(all_ratings)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ab76638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating statistics:\n",
      "Min rating: 1.0\n",
      "Max rating: 10.0\n",
      "Mean rating: 8.03\n",
      "Median rating: 8.00\n",
      "Unique ratings: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rating distribution:\n",
      "Rating 1.0: 489715 samples (1.59%)\n",
      "Rating 2.0: 191065 samples (0.62%)\n",
      "Rating 3.0: 223451 samples (0.72%)\n",
      "Rating 4.0: 963612 samples (3.12%)\n",
      "Rating 5.0: 851150 samples (2.76%)\n",
      "Rating 6.0: 2291516 samples (7.42%)\n",
      "Rating 7.0: 4983303 samples (16.13%)\n",
      "Rating 8.0: 7134345 samples (23.10%)\n",
      "Rating 9.0: 4844236 samples (15.68%)\n",
      "Rating 10.0: 8916924 samples (28.87%)\n"
     ]
    }
   ],
   "source": [
    "# Print basic statistics\n",
    "print(\"Rating statistics:\")\n",
    "print(f\"Min rating: {all_ratings.min()}\")\n",
    "print(f\"Max rating: {all_ratings.max()}\")\n",
    "print(f\"Mean rating: {all_ratings.mean():.2f}\")\n",
    "print(f\"Median rating: {np.median(all_ratings):.2f}\")\n",
    "print(f\"Unique ratings: {np.unique(all_ratings)}\")\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(all_ratings,\n",
    " bins=len(np.unique(all_ratings)),\n",
    " weights=np.ones_like(all_ratings)/len(all_ratings),\n",
    " edgecolor='black', )\n",
    "plt.title('Distribución de Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Tasa')\n",
    "plt.xticks(np.unique(all_ratings))\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# Check class distribution\n",
    "unique, counts = np.unique(all_ratings, return_counts=True)\n",
    "print(\"\\nRating distribution:\")\n",
    "for rating, count in zip(unique, counts):\n",
    "    print(f\"Rating {rating}: {count} samples ({count/len(all_ratings)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac5f4a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57bfa94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of high ratings per user: 27.714476340406847\n"
     ]
    }
   ],
   "source": [
    "n_users = {}\n",
    "# Count users with ratings >= 0.7\n",
    "for batch in train_loader:\n",
    "    high_rating_mask  = batch['rating'] >= 7\n",
    "    high_rating_users = batch['user_id'][high_rating_mask]\n",
    "    for user_id in high_rating_users:\n",
    "        user_id = int(user_id)\n",
    "        n_users[user_id] = n_users.get(user_id, 0) + 1\n",
    "\n",
    "# Calculate average\n",
    "average_high_ratings = sum(n_users.values()) / len(n_users) if n_users else 0\n",
    "print(f\"Average number of high ratings per user: {average_high_ratings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5206fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(path_model):\n",
    "    \"\"\"\n",
    "    Obtiene ultimo modelo entrenado.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    file_list = os.listdir(path_model)\n",
    "    if len(file_list) == 0: return None\n",
    "\n",
    "    index_list = [0]*len(file_list)\n",
    "    for i, file in enumerate(file_list):\n",
    "        index_list[i] = int(file.split(\".\")[0].split(\"checkpoint\")[1])\n",
    "        \n",
    "    max_idx= max(index_list)\n",
    "    return file_list[index_list.index(max_idx)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3f46f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_item_dimension: 323\n",
      "feature_user_dimension: 320\n",
      "actual_model: checkpoint0009.pth\n"
     ]
    }
   ],
   "source": [
    "print(f\"feature_item_dimension: {item_df.shape[1]}\")\n",
    "print(f\"feature_user_dimension: {user_df.shape[1]}\")\n",
    "\n",
    "#La primer columna corresponmde a los respectivos Ids\n",
    "num_user_features = user_df.shape[1]\n",
    "num_item_features = item_df.shape[1]\n",
    "dim_embedding = 256 #128\n",
    "\n",
    "path_model = \"../../models/TwoTowerEmb/\"\n",
    "\n",
    "model = UserBasesFiltering(\n",
    "    num_user_features,\n",
    "    num_item_features,\n",
    "    dim_embedding,\n",
    "    [256, 512],\n",
    "    0.5\n",
    ").to(device)\n",
    "#cargar siempre el ultimo.pth, es de tipo checkpoint000x.pth\n",
    "if True:\n",
    "    actual_model = get_model(path_model)\n",
    "    if actual_model is not None: \n",
    "        print(f\"actual_model: {actual_model}\")\n",
    "        checkpoint = torch.load(path_model + actual_model, weights_only=True)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc8662c",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4216f4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}(\\hat{y}, y) = \\mathbb{E}[w(y) (\\hat{y} - y)^2]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d0762b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityMSELoss:\n",
    "    def __init__(self, scaler=False):\n",
    "        self.cos = nn.CosineSimilarity(dim=1)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.scaler = scaler\n",
    "    \n",
    "    def __call__(self, user_ebatch, item_ebatch, ratings_batch):\n",
    "        score_pred = self.cos(user_ebatch, item_ebatch)\n",
    "        if self.scaler:\n",
    "            ratings_batch = ratings_batch/10\n",
    "        return self.loss(score_pred, ratings_batch)\n",
    "\n",
    "class WeightedMSELoss(torch.nn.Module):\n",
    "    def __init__(self, rating_weights, rating_scale = (0, 10), scale=(-1, 1)):\n",
    "        super().__init__()\n",
    "        self.rating_weights = rating_weights\n",
    "        self.mse = nn.MSELoss(reduction=\"none\")\n",
    "        self.rating_scale = rating_scale\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, user_ebatch, item_ebatch, ratings_batch):\n",
    "        # pred: (batch,)\n",
    "        # target: (batch,) ratings reales\n",
    "\n",
    "        rating_pred = (user_ebatch * item_ebatch).sum(dim=1)\n",
    "\n",
    "        w = torch.tensor(\n",
    "            [self.rating_weights[int(r.item())] for r in ratings_batch],\n",
    "            device=rating_pred.device,\n",
    "            dtype =rating_pred.dtype\n",
    "        )\n",
    "\n",
    "        if self.scale:\n",
    "            #Min max scaler en el intervalo -1 1\n",
    "            ratings_batch = ratings_batch - self.rating_scale[0]\n",
    "            ratings_batch = ratings_batch / (self.rating_scale[1] - self.rating_scale[0])\n",
    "            ratings_batch = ratings_batch * (self.scale[1] - self.scale[0]) + self.scale[0]\n",
    "\n",
    "\n",
    "        return torch.mean(w * self.mse(rating_pred, ratings_batch))\n",
    "\n",
    "\n",
    "class DotProductMSELoss(nn.Module):\n",
    "    def __init__(self, scaler=True):\n",
    "        super().__init__()\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.scale_ratings = scaler\n",
    "\n",
    "    def forward(self, user_ebatch, item_ebatch, ratings_batch):\n",
    "        score_pred = (user_ebatch * item_ebatch).sum(dim=1)\n",
    "\n",
    "        if self.scale_ratings:\n",
    "            ratings_batch = ratings_batch / 10.0  # o el max real\n",
    "\n",
    "        return self.loss(score_pred, ratings_batch)\n",
    "\n",
    "\n",
    "class Loss(torch.nn.Module):\n",
    "    def __init__(self, path_weights: str, rating_scale = (0, 10), scale=(-1, 1), margin=0.3, wloss = [1., 1.]):\n",
    "        super().__init__()\n",
    "        self.mse            = nn.MSELoss(reduction=\"none\")\n",
    "        self.rating_scale   = rating_scale\n",
    "        self.scale          = scale\n",
    "        self.margin         = margin\n",
    "        self.lambda1, self.lambda2 = wloss\n",
    "        self.w_freq         = self._get_wfreq(path_weights)\n",
    "\n",
    "    def forward(self, user_ebatch, item_ebatch, ratings_batch):\n",
    "        # pred:   (batch,)\n",
    "        # target: (batch,) ratings reales\n",
    "        #\n",
    "        rating_pred = (user_ebatch * item_ebatch).sum(dim=1)\n",
    "\n",
    "        if self.scale: #Min max scaler en el intervalo -1 1\n",
    "            ratings_batch = self._scale(ratings_batch)\n",
    "\n",
    "        l1 = self._pairwiseLoss(rating_pred, ratings_batch, self.margin)\n",
    "        l2 = self._weightedLoss(rating_pred, ratings_batch)\n",
    "    \n",
    "        return self.lambda1 * l1 + self.lambda2 * l2\n",
    "\n",
    "    def _scale(self, ratings_batch):\n",
    "        ratings_batch = ratings_batch - self.rating_scale[0]\n",
    "        ratings_batch = ratings_batch / (self.rating_scale[1] - self.rating_scale[0])\n",
    "        ratings_batch = ratings_batch * (self.scale[1] - self.scale[0]) + self.scale[0]\n",
    "        return ratings_batch\n",
    "\n",
    "    def _pairwiseLoss(self, pred, target, margin=0.5):\n",
    "        \"\"\" Diferencia entre pares consecutivos tal que |pred - target|> margin \"\"\"\n",
    "\n",
    "        #Estos son matrices de diferencias entre todos los pares posibles de ratings.\n",
    "        diff_target = target.unsqueeze(1) - target.unsqueeze(0)\n",
    "        diff_pred   = pred.unsqueeze(1)   - pred.unsqueeze(0)\n",
    "\n",
    "        mask = diff_target > margin   # solo pares con diferencia real\n",
    "        loss = F.relu(margin - diff_pred[mask])\n",
    "        return loss.mean() if mask.any() else 0.0\n",
    "    \n",
    "    def _weightedLoss(self, pred, target):\n",
    "        \"\"\"  L = sum(w * (pred - target)^2) \"\"\"\n",
    "        w = torch.tensor(\n",
    "            [self.w_freq[int(r.item())] for r in target],\n",
    "            device=pred.device,\n",
    "            dtype =pred.dtype\n",
    "        )\n",
    "        return torch.mean(w * self.mse(pred, target))\n",
    "\n",
    "    def _get_wfreq(self, path):\n",
    "        weights = {}\n",
    "\n",
    "        df = pd.read_csv(\n",
    "            path, \n",
    "            header=None,\n",
    "            names=[\"rating\", \"count\", \"normalized_freq\"]) \n",
    "\n",
    "        for r, p in zip(df[\"rating\"], df[\"normalized_freq\"]):\n",
    "            weights[int(r)] = 1.0 / np.sqrt(p)\n",
    "\n",
    "        # normalizar (MUY importante)\n",
    "        mean_w = np.mean(list(weights.values()))\n",
    "        weights = {r: w / mean_w for r, w in weights.items()}   #AUX SACO NORMALIZACION DE PESOS!\n",
    "        \n",
    "        w_scaled = {}\n",
    "        if self.scale: # sdignifica que ahora las claves van a estar en otro rango\n",
    "            for k, v in weights.items():\n",
    "                w_scaled[self._scale(k)] = v \n",
    "\n",
    "        return w_scaled\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c0600f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5510</td>\n",
       "      <td>0.000720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>122358</td>\n",
       "      <td>0.015978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>47213</td>\n",
       "      <td>0.006165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>54740</td>\n",
       "      <td>0.007148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>240599</td>\n",
       "      <td>0.031418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>209884</td>\n",
       "      <td>0.027407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>567503</td>\n",
       "      <td>0.074107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1236148</td>\n",
       "      <td>0.161421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1767299</td>\n",
       "      <td>0.230781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1196170</td>\n",
       "      <td>0.156201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2210480</td>\n",
       "      <td>0.288653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id    rating\n",
       "0         0     5510  0.000720\n",
       "1         1   122358  0.015978\n",
       "2         2    47213  0.006165\n",
       "3         3    54740  0.007148\n",
       "4         4   240599  0.031418\n",
       "5         5   209884  0.027407\n",
       "6         6   567503  0.074107\n",
       "7         7  1236148  0.161421\n",
       "8         8  1767299  0.230781\n",
       "9         9  1196170  0.156201\n",
       "10       10  2210480  0.288653"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rating_freq_test.csv/part-00000-a68a81fd-85b8-4332-86e4-7fdb54b6031c-c000.csv\n",
    "#insertar columnas user_id, item_id, rating\n",
    "pd.read_csv(\n",
    "    data_root + \"rating_freq_test.csv/part-00000-a68a81fd-85b8-4332-86e4-7fdb54b6031c-c000.csv\", \n",
    "    header=None, \n",
    "    names=[\"user_id\", \"item_id\", \"rating\"]\n",
    ")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41ef4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "#criterion = nn.CosineEmbeddingLoss()\n",
    "#criterion = SimilarityMSELoss(scaler=True)\n",
    "#criterion = DotProductMSELoss(scaler=False)\n",
    "#criterion = RatingMarginLoss(margin=0.7)\n",
    "#criterion = nn.MSELopath_modelss()\n",
    "\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#torch.save(weights, path + \"rating_weights.pt\")\n",
    "\n",
    "#criterion = WeightedMSELoss(weights)\n",
    "path_weights = data_root + \"rating_freq_test.csv/part-00000-a68a81fd-85b8-4332-86e4-7fdb54b6031c-c000.csv\"\n",
    "criterion = Loss(path_weights, margin=0.5)\n",
    "\n",
    "\n",
    "if False:\n",
    "    num_epochs = 32#256\n",
    "\n",
    "    epoch_init = 0\n",
    "    if actual_model is not None: epoch_init = checkpoint[\"epoch\"]\n",
    "\n",
    "    for epoch in range(epoch_init, num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "\n",
    "            # \"user_id\": \n",
    "            # \"item_id\": \n",
    "            # \"user_batch\": \n",
    "            # \"item_batch\": \n",
    "            # \"label\":  \n",
    "            # \"rating\": \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            #outputs = model(user_batch, item_batch)\n",
    "            user_embedding, item_embedding = model(batch[\"user_batch\"].to(device), batch[\"item_batch\"].to(device))\n",
    "\n",
    "            #loss    = criterion(user_embedding, item_embedding, target_batch.squeeze())\n",
    "            loss    = criterion(user_embedding, item_embedding, batch[\"rating\"].to(device))\n",
    "            #print(f\"epoch: {epoch} | Loss: {loss.item()}\")\n",
    "            assert not torch.isnan(loss), f\"Loss is NaN \\n user_batch: {batch['user_batch']} \\n user_min: {batch['user_batch'].min()} \\n item_batch: {batch['item_batch']} \\n item_min: {batch['item_batch'].min()} \\n target_batch: {batch['label']} \\n ratings_batch: {batch['rating']}\"\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "   \n",
    "        avg_loss = running_loss / len(train_loader) #running_loss / batch_size\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        #guardar el modelo.\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, f\"{path_model}checkpoint{epoch:04d}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27ed85f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss in epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a80983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with torch.no_grad():\n",
    "#    cos_scores = (user_embedding* item_embedding).sum(dim=1)\n",
    "#    print(cos_scores.mean(), cos_scores.std())\n",
    "#    \n",
    "#print(torch.quantile(cos_scores, torch.tensor([0.1, 0.5, 0.9])))\n",
    "#\n",
    "#\n",
    "#\n",
    "#count = 0\n",
    "#print(f\"quantile [0.1, 0.5, 0.9]\")\n",
    "#for batch in train_loader:\n",
    "#    count += 1\n",
    "#    if count > 20: break\n",
    "#    u_emb, i_emb = model(batch[\"user_batch\"], batch[\"item_batch\"])\n",
    "#\n",
    "#    cos_scores = (u_emb * i_emb).sum(dim=1)\n",
    "#\n",
    "#    print(f\"quantile ref, {torch.quantile(batch['rating'], torch.tensor([0.1, 0.5, 0.9]))}:   obtenido: {torch.quantile(cos_scores, torch.tensor([0.1, 0.5, 0.9]))}\")\n",
    "#    \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7221f93f",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6e2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b23e820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46168/2807039317.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_model+actual_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0077\n"
     ]
    }
   ],
   "source": [
    "#Cargo el modelo\n",
    "if True:\n",
    "    checkpoint = torch.load(path_model+actual_model)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0.0\n",
    "    for batch in test_loader:\n",
    "        user_batch, item_batch = batch[\"user_batch\"].to(device), batch[\"item_batch\"].to(device)\n",
    "\n",
    "        user_embedding, item_embedding = model(user_batch, item_batch)\n",
    "        # si y=-1 -> criterion = max(0,cos(x1,x2))\n",
    "\n",
    "        loss = criterion(user_embedding, item_embedding, batch[\"rating\"].to(device))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Test Loss: {total_loss / len(test_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a38c5c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating statistics:\n",
      "Min rating: 0.0\n",
      "Max rating: 10.0\n",
      "Mean rating: 8.00\n",
      "Median rating: 8.00\n",
      "Unique ratings: [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rating distribution:\n",
      "Rating 0.0: 28002 samples (0.36%)\n",
      "Rating 1.0: 122357 samples (1.59%)\n",
      "Rating 2.0: 47210 samples (0.61%)\n",
      "Rating 3.0: 54735 samples (0.71%)\n",
      "Rating 4.0: 240592 samples (3.13%)\n",
      "Rating 5.0: 209880 samples (2.73%)\n",
      "Rating 6.0: 567488 samples (7.39%)\n",
      "Rating 7.0: 1236119 samples (16.10%)\n",
      "Rating 8.0: 1767253 samples (23.01%)\n",
      "Rating 9.0: 1196147 samples (15.57%)\n",
      "Rating 10.0: 2210347 samples (28.78%)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Collect all ratings\n",
    "all_ratings = []\n",
    "for batch in test_loader:\n",
    "    all_ratings.extend(batch[\"rating\"].numpy())\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "all_ratings = np.array(all_ratings)\n",
    "\n",
    "# Print basic statistics\n",
    "print(\"Rating statistics:\")\n",
    "print(f\"Min rating: {all_ratings.min()}\")\n",
    "print(f\"Max rating: {all_ratings.max()}\")\n",
    "print(f\"Mean rating: {all_ratings.mean():.2f}\")\n",
    "print(f\"Median rating: {np.median(all_ratings):.2f}\")\n",
    "print(f\"Unique ratings: {np.unique(all_ratings)}\")\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(all_ratings,\n",
    " bins=len(np.unique(all_ratings)),\n",
    " weights=np.ones_like(all_ratings)/len(all_ratings),\n",
    " edgecolor='black', )\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(np.unique(all_ratings))\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# Check class distribution\n",
    "unique, counts = np.unique(all_ratings, return_counts=True)\n",
    "print(\"\\nRating distribution:\")\n",
    "for rating, count in zip(unique, counts):\n",
    "    print(f\"Rating {rating}: {count} samples ({count/len(all_ratings)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "577f6107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionScorer:\n",
    "    \"\"\"\n",
    "    Ejecuta inferencia del modelo y produce scores escalares.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, device, score_range=(0, 1)):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.s_min, self.s_max = score_range\n",
    "\n",
    "    def score_batch(self, user_batch, item_batch):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        scores : torch.Tensor shape [B]\n",
    "        \"\"\"\n",
    "        user_batch = user_batch.to(self.device)\n",
    "        item_batch = item_batch.to(self.device)\n",
    "\n",
    "        user_emb, item_emb = self.model(user_batch, item_batch)\n",
    "\n",
    "        # IMPLEMENTACIÓN REEMPLAZABLE\n",
    "        #scores = F.cosine_similarity(user_emb, item_emb, dim=1)\n",
    "        scores = (user_emb * item_emb).sum(dim=1).clamp(min=self.s_min, max=self.s_max)\n",
    "\n",
    "        return scores\n",
    "\n",
    "\n",
    "# aggregation.py\n",
    "from collections import defaultdict\n",
    "\n",
    "class UserInteractionStore:\n",
    "    \"\"\"\n",
    "    Almacena scores y labels agrupados por usuario.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pred    = defaultdict(list)\n",
    "        self.target  = defaultdict(list)\n",
    "        self.item_id = defaultdict(list)\n",
    "\n",
    "    def add_batch(self, user_ids, pred, target, items):\n",
    "        for u, s, y, i in zip(user_ids, pred, target, items):\n",
    "            uid = int(u)\n",
    "            self.pred[uid].append(float(s))\n",
    "            self.target[uid].append(int(y))\n",
    "            self.item_id[uid].append(int(i))\n",
    "\n",
    "    def users(self):\n",
    "        return self.pred.keys()\n",
    "\n",
    "    def get_user_data(self, user_id):\n",
    "        return np.array(self.pred[user_id]), np.array(self.target[user_id]), np.array(self.item_id[user_id])\n",
    "\n",
    "\n",
    "# topk.py\n",
    "import numpy as np\n",
    "\n",
    "def topk_indices(scores, k):\n",
    "    \"\"\"\n",
    "    Retorna índices de los top-k scores.\n",
    "    Complejidad: O(n)\n",
    "    \"\"\"\n",
    "    scores = np.asarray(scores)\n",
    "\n",
    "    if len(scores) <= k:\n",
    "        return np.argsort(scores)[::-1]\n",
    "\n",
    "    idx = np.argpartition(scores, -k)[-k:]\n",
    "    return idx[np.argsort(scores[idx])[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "286b8872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDCG@10': 0.9987451492043701,\n",
       " 'Precision@10': 0.6394497770836008,\n",
       " 'Recall@10': 0.8891970610870356,\n",
       " 'HitRate@10': 0.9996814695457427}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Agrega el directorio padre al path de Python\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from utils import (\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    "    hit_rate_at_k,\n",
    "    apk,\n",
    "    ndcg_at_k,\n",
    "    mae,\n",
    "    mse,\n",
    "    rmse\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# evaluator.py\n",
    "class Evaluator:\n",
    "    def __init__(self, scorer, k=10, relevant_threshold=0.7):\n",
    "        self.scorer = scorer\n",
    "        self.k = k\n",
    "        self.relevant_threshold = relevant_threshold\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        store = UserInteractionStore()\n",
    "\n",
    "        self.scorer.model.eval() # este es nuestro modelo entrenado\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                pred_scores = self.scorer.score_batch(batch[\"user_batch\"].to(device), batch[\"item_batch\"].to(device))\n",
    "                #Internamente guarda por cada usuario.\n",
    "                store.add_batch(\n",
    "                    user_ids= batch[\"user_id\"].cpu(),\n",
    "                    pred    = pred_scores.cpu()/10, #(0,1)\n",
    "                    target  = batch[\"rating\"].cpu(),#(0,10)\n",
    "                    items   = batch[\"item_id\"].cpu(),\n",
    "                )\n",
    "\n",
    "        return self._compute_metrics(store)\n",
    "\n",
    "    def _compute_metrics(self, store):\n",
    "        ndcgs      = self._compute_metric_at_k(store, ndcg_at_k)\n",
    "        precisions = self._compute_metric_at_k(store, precision_at_k)\n",
    "        recalls    = self._compute_metric_at_k(store, recall_at_k)\n",
    "        hits       = self._compute_metric_at_k(store, hit_rate_at_k)\n",
    "\n",
    "        return {\n",
    "            f\"NDCG@{self.k}\":       float(np.mean(ndcgs)),\n",
    "            f\"Precision@{self.k}\":  float(np.mean(precisions)),\n",
    "            f\"Recall@{self.k}\":     float(np.mean(recalls)),\n",
    "            f\"HitRate@{self.k}\":    float(np.mean(hits)),\n",
    "        }\n",
    "\n",
    "    def _sort_items(self, items, scores):\n",
    "        \"\"\"\n",
    "        Recibe dos listas ina de items otra de scores, organiza los items segun los scores siendo el primero elemento el de mayor score.\n",
    "        \"\"\"\n",
    "        sort_idx = np.argsort(scores)[::-1]\n",
    "        return items[sort_idx], scores[sort_idx]\n",
    "        \n",
    "\n",
    "    def _compute_metric_at_k(self, store, metric_at_k):\n",
    "        \"\"\" Computa la metrica por cada usuari\"\"\"\n",
    "        metric = []\n",
    "        for u in store.users():\n",
    "            #prediccion de score, score real, items del usuario\n",
    "            preds, targets, items = store.get_user_data(u)  #notar que no importa el rango de los ratings sino un orden de relevantes.\n",
    "            #Obtengo los items mas relevantes.\n",
    "            #print(f\"targets: {targets}\")\n",
    "            #print(f\"preds: {preds}\")\n",
    "            item_relevants = items[targets >= self.relevant_threshold]\n",
    "            #Ordeno los items segun los scores, para obtener los topk items recomendados\n",
    "            items, preds = self._sort_items(items, preds)\n",
    "\n",
    "            # metric(items_recomendados, _items_relevantes) al primero tomo los topk, asume que hay almenos k items\n",
    "            metric.append(metric_at_k(items, list(item_relevants), self.k))\n",
    "\n",
    "        return metric\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "scorer    = InteractionScorer(model, device)\n",
    "evaluator = Evaluator(scorer, k=10, relevant_threshold=0.4)\n",
    "evaluator.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45c1983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Test Loss: 0.0509\n",
      "MSE Test Loss: 0.2193\n",
      "RMSE Test Loss: 0.0583\n"
     ]
    }
   ],
   "source": [
    "#Ahora calculos los MSE, RMSE, MAE\n",
    "\n",
    "#    mae,\n",
    "#    mse,\n",
    "#    rmse\n",
    "\n",
    "prediction = InteractionScorer(model, device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    mae_total_loss = 0.0\n",
    "    mse_total_loss = 0.0\n",
    "    rmse_total_loss = 0.0\n",
    "    for batch in test_loader:\n",
    "        user_batch, item_batch = batch[\"user_batch\"].to(device), batch[\"item_batch\"].to(device)\n",
    "\n",
    "        \n",
    "        pred = prediction.score_batch(user_batch, item_batch)\n",
    "\n",
    "        mae_loss = mae(pred*10, batch[\"rating\"].to(device))\n",
    "        mae_total_loss += mae_loss.item()\n",
    "\n",
    "        mse_loss = mse(pred*10, batch[\"rating\"].to(device))\n",
    "        mse_total_loss += mse_loss.item()\n",
    "        \n",
    "        rmse_loss = rmse(pred*10, batch[\"rating\"].to(device))\n",
    "        rmse_total_loss += rmse_loss.item()\n",
    "\n",
    "    print(f\"MAE Test Loss: {mae_total_loss / len(test_loader):.4f}\")\n",
    "    print(f\"MSE Test Loss: {mse_total_loss / len(test_loader):.4f}\")\n",
    "    print(f\"RMSE Test Loss: {rmse_total_loss / len(test_loader):.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c10f6a7",
   "metadata": {},
   "source": [
    "Una poronga, no esta aprendiendo, puede que sea por los datos no balanceados, ahay muchos buenos ratingsm analizarlos todo y ser que hacer!\n",
    "\n",
    "tAMBIEN chequear las metricas de evaluacion pero con ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994da1f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df07ecde",
   "metadata": {},
   "source": [
    "BUSCAR\n",
    "\n",
    "\n",
    "✔ Google:\n",
    "\n",
    "Two-Tower Neural Networks for Large-Scale Recommendation\n",
    "\n",
    "✔ Meta:\n",
    "\n",
    "DSSM / Contrastive Retrieval\n",
    "\n",
    "✔ Netflix:\n",
    "\n",
    "Practical Lessons from Predicting Clicks on Ads at Facebook\n",
    "\n",
    "✔ PyTorch:\n",
    "\n",
    "CosineEmbeddingLoss official docs\n",
    "\n",
    "✔ Spotify:\n",
    "\n",
    "ANN-based recommendation retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51dd67e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6130a1a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
